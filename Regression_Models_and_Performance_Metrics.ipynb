{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
        "\n",
        "ANS- Simple Linear Regression (SLR) is a statistical technique used to study the relationship between two variables â€” one independent variable (X) and one dependent variable (Y). It helps in finding the best-fitting straight line that describes how the dependent variable changes with respect to the independent variable. The relationship between them is expressed using the equation,\n",
        "\n",
        "ğ‘Œ\n",
        "=ğ‘\n",
        "+\n",
        "ğ‘\n",
        "ğ‘‹\n",
        "\n",
        "where\n",
        "ğ‘\n",
        "a represents the intercept (the value of Y when X is zero) and\n",
        "ğ‘\n",
        "b represents the slope (the rate at which Y changes for each unit change in X). The main purpose of Simple Linear Regression is to predict the value of one variable based on the known value of another and to understand the strength and direction of their relationship. For example, it can be used to predict a studentâ€™s marks based on the number of hours studied. Overall, SLR is widely used for prediction, trend analysis, and making data-driven decisions."
      ],
      "metadata": {
        "id": "24lsQd4qUu0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "ANS- Simple Linear Regression (SLR) is based on several key assumptions that must be met for the model to produce reliable and accurate results. These assumptions ensure that the relationship between the variables is correctly represented. The main assumptions are:\n",
        "\n",
        "**Linearity:** The relationship between the independent variable (X) and the dependent variable (Y) should be linear â€” meaning Y changes at a constant rate with X.\n",
        "\n",
        "**Independence:** The observations in the dataset should be independent of each other; one observation should not influence another.\n",
        "\n",
        "**Homoscedasticity:** The variance of the residuals (errors) should remain constant across all values of the independent variable.\n",
        "\n",
        "**Normality of Errors:** The residuals (differences between observed and predicted values) should be normally distributed.\n",
        "\n",
        "**No Multicollinearity:** Since Simple Linear Regression involves only one independent variable, this assumption is automatically satisfied."
      ],
      "metadata": {
        "id": "Iq0SbTeOUuxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.**\n",
        "\n",
        "ANS- The mathematical equation for a Simple Linear Regression (SLR) model is\n",
        "\n",
        "ğ‘Œ\n",
        "=ğ‘\n",
        "+\n",
        "ğ‘\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘’\n",
        "\n",
        "In this equation, Y represents the dependent variable, which is the outcome or value we aim to predict. X is the independent variable, which is used to explain or predict the changes in Y. The term a is the intercept, showing the value of Y when X is zero, and it indicates where the regression line crosses the Y-axis. The coefficient b is the slope of the line, representing how much Y changes for a one-unit increase in X; it shows the direction and strength of the relationship between the two variables. Finally, e is the error term, which captures the difference between the observed and predicted values of Y, accounting for random variations that cannot be explained by X. Together, these terms describe a straight-line relationship between two variables in a simple and interpretable form."
      ],
      "metadata": {
        "id": "ChljIy0wUuuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied.**\n",
        "\n",
        "ANS-A real-world example of applying Simple Linear Regression is in predicting a studentâ€™s exam score based on the number of study hours. In this case, the dependent variable (Y) is the exam score, and the independent variable (X) is the number of hours the student studies. By collecting data from several students about how long they studied and the marks they received, a simple linear regression model can be built to find a relationship between study time and exam performance. The model can then be used to predict future studentsâ€™ scores based on how many hours they plan to study. This helps in understanding whether studying more hours leads to higher marks and how strongly the two variables are related."
      ],
      "metadata": {
        "id": "P_yEz7YNUGN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: What is the method of least squares in linear regression?**\n",
        "\n",
        "ANS- The method of least squares is a mathematical technique used in linear regression to find the best-fitting line through a set of data points. It works by minimizing the sum of the squares of the differences (called residuals) between the actual observed values and the values predicted by the regression line. In other words, it finds the line where the total squared error between predicted and actual values is the smallest possible.\n",
        "\n",
        "This method ensures that both positive and negative errors do not cancel each other out and that larger errors are given more weight because they are squared. By applying the least squares method, we can determine the most accurate values of the intercept (a) and slope (b) in the regression equation\n",
        "\n",
        "ğ‘Œ\n",
        "=ğ‘\n",
        "+\n",
        "ğ‘\n",
        "ğ‘‹\n",
        "\n",
        " In summary, the method of least squares helps in estimating the regression line that best represents the relationship between the variables."
      ],
      "metadata": {
        "id": "pf_dyASyUGLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "ANS- Logistic Regression is a statistical method used to predict the outcome of a categorical dependent variable, particularly when the outcome is binary, such as yes or no, pass or fail, or 0 and 1. Unlike linear regression, which predicts continuous values, logistic regression estimates the probability that a given input belongs to a particular category. It uses the logistic or sigmoid function, which produces an S-shaped curve, ensuring that the predicted values always lie between 0 and 1. The equation for logistic regression is\n",
        "\n",
        "ğ‘ƒ(\n",
        "ğ‘Œ\n",
        "=1)\n",
        "=1/\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "(\n",
        "ğ‘\n",
        "+\n",
        "ğ‘\n",
        "ğ‘‹\n",
        ")\n",
        "where\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘Œ\n",
        "=1)\n",
        "P(Y=1) represents the probability of the event occurring. The key difference between logistic and linear regression is that linear regression is used for continuous outcomes and fits a straight line, while logistic regression is used for categorical outcomes and fits an S-shaped curve. Moreover, linear regression assumes normally distributed errors, whereas logistic regression assumes a binomial distribution. In summary, logistic regression is used to predict probabilities and classify outcomes rather than estimating numeric values."
      ],
      "metadata": {
        "id": "JSycMlCrUGI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.**\n",
        "\n",
        "ANS- Three common evaluation metrics used to assess the performance of regression models are Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (RÂ²).\n",
        "\n",
        "1. **Mean Absolute Error (MAE):**\n",
        "MAE measures the average absolute difference between the predicted values and the actual values. It shows how much the predictions deviate from the real data on average. A lower MAE indicates better model accuracy.\n",
        "\n",
        "2. **Mean Squared Error (MSE):**\n",
        "MSE calculates the average of the squared differences between the predicted and actual values. Squaring the errors gives more weight to larger mistakes, making MSE useful when you want to penalize large errors more strongly.\n",
        "\n",
        "3. **R-squared (RÂ²):**\n",
        "R-squared, also known as the coefficient of determination, indicates how well the regression model explains the variability of the dependent variable. It ranges from 0 to 1, where a value closer to 1 means the model explains most of the variation in the data."
      ],
      "metadata": {
        "id": "Gfco3PFzV0_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "ANS- The R-squared (RÂ²) metric in regression analysis is used to measure how well the independent variable(s) explain the variability of the dependent variable. It represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). The value of R-squared ranges from 0 to 1, where a value closer to 1 indicates a better fit of the model to the data.\n",
        "\n",
        "For example, an R-squared value of 0.85 means that 85% of the variation in the dependent variable is explained by the model, while the remaining 15% is due to other unexplained factors or random noise. In simple terms, the purpose of R-squared is to show how well the regression line fits the data â€” higher values mean a stronger relationship between the variables, while lower values indicate a weaker fit."
      ],
      "metadata": {
        "id": "-JGbvyeQV6yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "xyhTkkqHV64y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GXUHH-jMUp8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b684516-6f3f-4ec7-a4dc-7412c980e419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope: 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "# X = independent variable (reshaped into 2D array as required by scikit-learn)\n",
        "# Y = dependent variable\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Creating and fitting the Simple Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Getting the slope and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Printing the results\n",
        "print(\"Slope:\", slope)\n",
        "print(\"Intercept:\", intercept)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "ANS- In a Simple Linear Regression model, the coefficients â€” the slope and the intercept â€” describe the relationship between the independent variable (X) and the dependent variable (Y).\n",
        "\n",
        "The intercept (a) represents the predicted value of Y when X is equal to zero. It shows where the regression line crosses the Y-axis. In other words, it is the starting point or baseline value of the dependent variable when there is no influence from the independent variable.\n",
        "\n",
        "The slope (b) indicates how much Y changes for every one-unit increase in X. If the slope is positive, it means that as X increases, Y also increases, showing a direct relationship. If the slope is negative, it means that as X increases, Y decreases, showing an inverse relationship."
      ],
      "metadata": {
        "id": "lUTEr-1FW981"
      }
    }
  ]
}